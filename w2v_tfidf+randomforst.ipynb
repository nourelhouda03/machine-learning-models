{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"w2v/tfidf+randomforst.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":527},"id":"VV1VH-j-2-f2","executionInfo":{"status":"error","timestamp":1627942837278,"user_tz":-120,"elapsed":8524,"user":{"displayName":"Nourelhouda Chiker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIRsJ2cLZ_GIRXLQrpGrOh3S-krSIQBGU8Hb_WPA=s64","userId":"04099869123671146684"}},"outputId":"f01b80a6-897b-471e-cf19-49143b689d41"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!pip install  alphabet_detector \n","!pip install pyarabic\n","import nltk \n","nltk.download('stopwords')\n","nltk.download('punkt')\n","import pandas as pd\n","# Load the dataset into a pandas dataframe.\n","df = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/d20.xlsx\")\n","\n","from alphabet_detector import AlphabetDetector\n","import re\n","from nltk.corpus import stopwords\n","from textblob import TextBlob\n","from nltk.stem.isri import ISRIStemmer\n","\n","#remove any othe language letters\n","def keep_only_arabic(text):\n","    ad = AlphabetDetector()\n","    clean_lines = list()\n","    for line in text.splitlines():\n","        clean_line = list()\n","        for word in line.split():\n","            if len(word) > 1:\n","                if ad.is_arabic(word):\n","                    if word.isalpha():\n","                        clean_line.append(word)\n","        clean_lines.append(' '.join(clean_line))\n","    return '\\n'.join(clean_lines)\n","\n","# remove empty lines\n","def remove_empty_lines(text):\n","    lines = [s.rstrip() for s in text.split(\"\\n\") if s.rstrip()]\n","    return '\\n'.join(lines)\n","\n","def remove_emoji(string):\n","    emoji_pattern = re.compile(\"[\"\n","                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n","                               u\"\\U00002702-\\U000027B0\"\n","                               u\"\\U00002702-\\U000027B0\"\n","                               u\"\\U000024C2-\\U0001F251\"\n","                               u\"\\U0001f926-\\U0001f937\"\n","                               u\"\\U00010000-\\U0010ffff\"\n","                               u\"\\u2640-\\u2642\"\n","                               u\"\\u2600-\\u2B55\"\n","                               u\"\\u200d\"\n","                               u\"\\u23cf\"\n","                               u\"\\u23e9\"\n","                               u\"\\u231a\"\n","                               u\"\\ufe0f\"  # dingbats\n","                               u\"\\u3030\"\n","                               \"]+\", flags=re.UNICODE)\n","    return emoji_pattern.sub(r'', string)\n","import pyarabic.araby as araby\n","def normalizeArabic(text):\n","    text = text.strip()\n","    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n","    text = re.sub(\"ى\", \"ي\", text)\n","    text = re.sub(\"ؤ\", \"ء\", text)\n","    text = re.sub(\"ئ\", \"ء\", text)\n","    text = re.sub(\"ة\", \"ه\", text)\n","    noise = re.compile(\"\"\" ّ    | # Tashdid\n","                             َ    | # Fatha\n","                             ً    | # Tanwin Fath\n","                             ُ    | # Damma\n","                             ٌ    | # Tanwin Damm\n","                             ِ    | # Kasra\n","                             ٍ    | # Tanwin Kasr\n","                             ْ    | # Sukun\n","                             ـ     # Tatwil/Kashida\n","                         \"\"\", re.VERBOSE)\n","    text = re.sub(noise, '', text)\n","    text = re.sub(r'(.)\\1+', r\"\\1\", text) # Remove longation\n","    return araby.strip_tashkeel(text)\n","    \n","#delete everything except text \n","def char_rmvl(sentence):\n","  sen_split = sentence.split()\n","  for idx1,word in enumerate(sen_split):       \n","             sen_split[idx1] = re.sub('[^a-zا-ي]', '', word)       \n","  sentence = ' '.join(sen_split)    \n","  return sentence \n","stops = set(stopwords.words(\"arabic\"))\n","stop_word_comp = {\"،\",\"آض\",\"آمينَ\",\"آه\",\"آهاً\",\"آي\",\"أ\",\"أب\",\"أجل\",\"أجمع\",\"أخ\",\"أخذ\",\"أصبح\",\n","                  \"أضحى\",\"أقبل\",\"أقل\",\"أكثر\",\"ألا\",\"أم\",\"أما\",\"أمامك\",\"أمامكَ\",\"أمسى\",\"أمّا\",\"أن\",\"أنا\",\"أنت\",\"\",\"أنتما\",\"أنتن\",\"أنتِ\",\n","                  \"أنشأ\",\"أنّى\",\"أو\",\"أوشك\",\"أولئك\",\"أولئكم\",\"أولاء\",\"أولالك\",\"أوّهْ\",\"أي\",\"أيا\",\"أين\",\"أينما\",\"أيّ\",\"أَنَّ\",\"أََيُّ\",\"أُفٍّ\",\"إذ\",\"إذا\",\n","                  \"إذاً\",\"إذما\",\"إذن\",\"إلى\",\"إليكم\",\"إليكما\",\"إليكنّ\",\"إليكَ\",\"إلَيْكَ\",\"إلّا\",\"إمّا\",\"إن\",\"إنّما\",\"إي\",\"إياك\",\"إياكم\",\"إياكما\",\"إياكن\",\n","                  \"إيانا\",\"إياه\",\"إياها\",\"إياهم\",\"إياهما\",\"إياهن\",\"إياي\",\"إيهٍ\",\"إِنَّ\",\"ا\",\"ابتدأ\",\"اثر\",\"اجل\",\"احد\",\"اخرى\",\"اخلولق\",\"اذا\",\"اربعة\",\n","                  \"ارتدّ\",\"استحال\",\"اطار\",\"اعادة\",\"اعلنت\",\"اف\",\"اكثر\",\"اكد\",\"الألاء\",\"الألى\",\"الا\",\"الاخيرة\",\"الان\",\"الاول\",\"الاولى\",\"التى\",\"التي\",\n","                  \"الثاني\",\"الثانية\",\"الذاتي\",\"الذى\",\"الذي\",\"الذين\",\"السابق\",\"الف\",\"اللائي\",\"اللاتي\",\"اللتان\",\"اللتيا\",\"اللتين\",\"اللذان\",\"اللذين\",\"اللواتي\",\n","                  \"الماضي\",\"المقبل\",\"الوقت\",\"الى\",\"اليوم\",\"اما\",\"امام\",\"امس\",\"ان\",\"انبرى\",\"انقلب\",\"انه\",\"انها\",\"او\",\"اول\",\"اي\",\"ايار\",\"ايام\",\n","                  \"ايضا\",\"ب\",\"بات\",\"باسم\",\"بان\",\"بخٍ\",\"برس\",\"بسبب\",\"بسّ\",\"بشكل\",\"بضع\",\"بطآن\",\"بعد\",\"بعض\",\"بك\",\"بكم\",\"بكما\",\"بكن\",\n","                  \"بل\",\"بلى\",\"بما\",\"بماذا\",\"بمن\",\"بن\",\"بنا\",\"به\",\"بها\",\"بي\",\"بيد\",\"بين\",\"بَسْ\",\"بَلْهَ\",\"بِئْسَ\",\"تانِ\",\"تانِك\",\"تبدّل\",\"تجاه\",\"تحوّل\",\n","                  \"تلقاء\",\"تلك\",\"تلكم\",\"تلكما\",\"تم\",\"تينك\",\"تَيْنِ\",\"تِه\",\"تِي\",\"ثلاثة\",\"ثم\",\"ثمّ\",\"ثمّة\",\"ثُمَّ\",\"جعل\",\"جلل\",\"جميع\",\"جير\",\"حار\",\"حاشا\",\n","                  \"حاليا\",\"حاي\",\"حتى\",\"حرى\",\"حسب\",\"حم\",\"حوالى\",\"حول\",\"حيث\",\"حيثما\",\"حين\",\"حيَّ\",\"حَبَّذَا\",\"حَتَّى\",\"حَذارِ\",\"خلا\",\"خلال\",\"دون\",\n","                  \"دونك\",\"ذا\",\"ذات\",\"ذاك\",\"ذانك\",\"ذانِ\",\"ذلك\",\"ذلكم\",\"ذلكما\",\"ذلكن\",\"ذو\",\"ذوا\",\"ذواتا\",\"ذواتي\",\"ذيت\",\"ذينك\",\"ذَيْنِ\",\"ذِه\",\"ذِي\",\n","                  \"راح\",\"رجع\",\"رويدك\",\"ريث\",\"رُبَّ\",\"زيارة\",\"سبحان\",\"سرعان\",\"سنة\",\"سنوات\",\"سوف\",\"سوى\",\"سَاءَ\",\"سَاءَمَا\",\"شبه\",\"شخصا\",\"شرع\",\n","                  \"شَتَّانَ\",\"صار\",\"صباح\",\"صفر\",\"صهٍ\",\"صهْ\",\"ضد\",\"ضمن\",\"طاق\",\"طالما\",\"طفق\",\"طَق\",\"ظلّ\",\"عاد\",\"عام\",\"عاما\",\"عامة\",\"عدا\",\n","                  \"عدة\",\"عدد\",\"عدم\",\"عسى\",\"عشر\",\"عشرة\",\"علق\",\"على\",\"عليك\",\"عليه\",\"عليها\",\"علًّ\",\"عن\",\"عند\",\"عندما\",\"عوض\",\"عين\",\"عَدَسْ\",\n","                  \"عَمَّا\",\"غدا\",\"غير\",\"ـ\",\"ف\",\"فان\",\"فلان\",\"فو\",\"فى\",\"في\",\"فيم\",\"فيما\",\"فيه\",\"فيها\",\"قال\",\"قام\",\"قبل\",\"قد\",\"قطّ\",\"قلما\",\"قوة\",\"كأنّما\",\n","                  \"كأين\",\"كأيّ\",\"كأيّن\",\"كاد\",\"كان\",\"كانت\",\"كذا\",\"كذلك\",\"كرب\",\"كل\",\"كلا\",\"كلاهما\",\"كلتا\",\"كلم\",\"كليكما\",\"كليهما\",\"كلّما\",\"كلَّا\",\"كم\",\n","                  \"كما\",\"كي\",\"كيت\",\"كيف\",\"كيفما\",\"كَأَنَّ\",\"كِخ\",\"لئن\",\"لا\",\"لات\",\"لاسيما\",\"لدن\",\"لدى\",\"لعمر\",\"لقاء\",\"لك\",\"لكم\",\"لكما\",\"لكن\",\n","                  \"لكنَّما\",\"لكي\",\"لكيلا\",\"للامم\",\"لم\",\"لما\",\"لمّا\",\"لن\",\"لنا\",\"له\",\"لها\",\"لو\",\"لوكالة\",\"لولا\",\"لوما\",\"لي\",\"لَسْتَ\",\"لَسْتُ\",\"لَسْتُم\",\"لَسْتُمَا\",\n","                  \"لَسْتُنَّ\",\"لَسْتِ\",\"لَسْنَ\",\"لَعَلَّ\",\"لَكِنَّ\",\"لَيْتَ\",\"لَيْسَ\",\"لَيْسَا\",\"لَيْسَتَا\",\"لَيْسَتْ\",\"لَيْسُوا\",\"لَِسْنَا\",\"ما\",\"ماانفك\",\"مابرح\",\"مادام\",\"ماذا\",\"مازال\",\n","                  \"مافتئ\",\"مايو\",\"متى\",\"مثل\",\"مذ\",\"مساء\",\"مع\",\"معاذ\",\"مقابل\",\"مكانكم\",\"مكانكما\",\"مكانكنّ\",\"مكانَك\",\"مليار\",\"مليون\",\"مما\",\"ممن\",\n","                  \"من\",\"منذ\",\"منها\",\"مه\",\"مهما\",\"مَنْ\",\"مِن\",\"نحن\",\"نحو\",\"نعم\",\"نفس\",\"نفسه\",\"نهاية\",\"نَخْ\",\"نِعِمّا\",\"نِعْمَ\",\"ها\",\"هاؤم\",\"هاكَ\",\"هاهنا\",\n","                  \"هبّ\",\"هذا\",\"هذه\",\"هكذا\",\"هل\",\"هلمَّ\",\"هلّا\",\"هم\",\"هما\",\"هن\",\"هنا\",\"هناك\",\"هنالك\",\"هو\",\"هي\",\"هيا\",\"هيت\",\"هيّا\",\"هَؤلاء\",\n","                  \"هَاتانِ\",\"هَاتَيْنِ\",\"هَاتِه\",\"هَاتِي\",\"هَجْ\",\"هَذا\",\"هَذانِ\",\"هَذَيْنِ\",\"هَذِه\",\"هَذِي\",\"هَيْهَاتَ\",\"و\",\"و6\",\"وا\",\"واحد\",\"واضاف\",\"واضافت\",\n","                  \"واكد\",\"وان\",\"واهاً\",\"واوضح\",\"وراءَك\",\"وفي\",\"وقال\",\"وقالت\",\"وقد\",\"وقف\",\"وكان\",\"وكانت\",\"ولا\",\"ولم\",\"ومن\",\"مَن\",\"وهو\",\n","                  \"وهي\",\"ويكأنّ\",\"وَيْ\",\"وُشْكَانََ\",\"يكون\",\"يمكن\",\"يوم\",\"ّأيّان\",\"أنتم\" , 'إذ', 'إذا', 'إذما', 'إذن', 'أف', 'أقل', 'أكثر', 'ألا', 'إلا', 'التي', 'الذي', \n","                  'الذين', 'اللاتي', 'اللائي', 'اللتان', 'اللتيا', 'اللتين', 'اللذان', 'اللذين', \n","                    'اللواتي', 'إلى', 'إليك', 'إليكم', 'إليكما', 'إليكن', 'أم', 'أما', 'أما', 'إما', 'أن', 'إن', 'إنا', 'أنا', 'أنت', 'أنتم', 'أنتما', 'أنتن', 'إنما', 'إنه', 'أنى', 'أنى',\n","                    'آه', 'آها', 'أو', 'أولاء', 'أولئك', 'أوه', 'آي', 'أي', 'أيها', 'إي', 'أين', 'أين', 'أينما', 'إيه', 'بخ', 'بس', 'بعد', 'بعض', 'بك', 'بكم', 'بكم', 'بكما', 'بكن',\n","                    'بل', 'بلى', 'بما', 'بماذا', 'بمن', 'بنا', 'به', 'بها', 'بهم', 'بهما', 'بهن', 'بي', 'بين', 'بيد', 'تلك', 'تلكم', 'تلكما', 'ته', 'تي', 'تين', 'تينك', 'ثم', 'ثمة', 'حاشا',\n","                    'حبذا', 'حتى', 'حيث', 'حيثما', 'حين', 'خلا', 'دون', 'ذا', 'ذات', 'ذاك', 'ذان', 'ذانك', 'ذلك', 'ذلكم', 'ذلكما', 'ذلكن', 'ذه', 'ذو', 'ذوا', 'ذواتا', 'ذواتي', 'ذي', 'ذين', \n","                    'ذينك', 'ريث', 'سوف', 'سوى', 'شتان', 'عدا', 'عسى', 'عل', 'على', 'عليك', 'عليه', 'عما', 'عن', 'عند', 'غير', 'فإذا', 'فإن', 'فلا', 'فمن', 'في', 'فيم', 'فيما', 'فيه', \n","                    'فيها', 'قد', 'كأن', 'كأنما', 'كأي', 'كأين', 'كذا', 'كذلك', 'كل', 'كلا', 'كلاهما', 'كلتا', 'كلما', 'كليكما', 'كليهما', 'كم', 'كم', 'كما', 'كي', 'كيت', 'كيف', 'كيفما', 'لا',\n","                    'لاسيما', 'لدى', 'لست', 'لستم', 'لستما', 'لستن', 'لسن', 'لسنا', 'لعل', 'لك', 'لكم', 'لكما', 'لكن', 'لكنما', 'لكي', 'لكيلا', 'لم', 'لما', 'لن', 'لنا', 'له', 'لها', 'لهم', 'لهما', \n","                    'لهن', 'لو', 'لولا', 'لوما', 'لي', 'لئن', 'ليت', 'ليس', 'ليسا', 'ليست', 'ليستا', 'ليسوا', 'ما', 'ماذا', 'متى', 'مذ', 'مع', 'مما', 'ممن', 'من', 'منه', 'منها', 'منذ', 'مه', 'مهما',\n","                    'نحن', 'نحو', 'نعم', 'ها', 'هاتان', 'هاته', 'هاتي', 'هاتين', 'هاك', 'هاهنا', 'هذا', 'هذان', 'هذه', 'هذي', 'هذين', 'هكذا', 'هل', 'هلا', 'هم', 'هما', 'هن', 'هنا', 'هناك', 'هنالك',\n","                    'هو', 'هؤلاء', 'هي', 'هيا', 'هيت', 'هيهات', 'والذي', 'والذين', 'وإذ', 'وإذا', 'وإن', 'ولا', 'ولكن', 'ولو', 'وما', 'ومن', 'وهو', 'يا', 'يمالى', 'قل', 'كثر', 'ألي', 'ليك', 'ليكم', \n","                    'نتيا', 'نتوما', 'رانا' ,'بصح', 'هوما', 'وين', 'أمبعد', 'أومبعد', 'شوية', 'شويا', 'وش', 'واش', 'بوش', 'بواش','و'}\n","def remove_stop_words(text):\n","    zen = TextBlob(text)\n","    words = zen.words\n","    return \" \".join([w for w in words if not w in stops and not w in stop_word_comp and len(w) >= 2])\n","\n","\n","def all_togther(text):\n","  #text = keep_only_arabic(text)\n","  #text = remove_empty_lines(text)\n","  text = remove_emoji(text)\n","  text = normalizeArabic(text)\n","  text = char_rmvl(text)\n","  #text = text.lower()\n","  text = remove_stop_words(text)\n","  text = ISRIStemmer().suf32(text)\n","  return text\n","\n","\n","df['label'] = df['label'].apply(lambda x:all_togther(x))\n","nan_value = float(\"NaN\")\n","df.replace(\"\", nan_value, inplace=True)\n","df.dropna(subset = [\"label\"], inplace=True)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: alphabet_detector in /usr/local/lib/python3.7/dist-packages (0.0.7)\n","Requirement already satisfied: pyarabic in /usr/local/lib/python3.7/dist-packages (0.6.11)\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-50a079d72792>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mall_togther\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0mnan_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NaN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4212\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4213\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","\u001b[0;32m<ipython-input-18-50a079d72792>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mall_togther\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0mnan_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NaN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-50a079d72792>\u001b[0m in \u001b[0;36mall_togther\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;31m#text = keep_only_arabic(text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0;31m#text = remove_empty_lines(text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_emoji\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalizeArabic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_rmvl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-50a079d72792>\u001b[0m in \u001b[0;36mremove_emoji\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m     56\u001b[0m                                \u001b[0;34mu\"\\u3030\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                                \"]+\", flags=re.UNICODE)\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0memoji_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyarabic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maraby\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0maraby\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalizeArabic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"]}]},{"cell_type":"code","metadata":{"id":"u0vo5T4O8LqR","executionInfo":{"status":"ok","timestamp":1627940298540,"user_tz":-120,"elapsed":425,"user":{"displayName":"Nourelhouda Chiker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIRsJ2cLZ_GIRXLQrpGrOh3S-krSIQBGU8Hb_WPA=s64","userId":"04099869123671146684"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","df['hate ']= df['hate '].map({'yes':1,'no':0 })\n","\n","df.sample(5)\n","X_train, X_test, y_train, y_test = train_test_split(df['comments'], df['hate '], test_size=0.2, stratify=df['hate '])"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"4JkK1_ZZB6mz","executionInfo":{"status":"ok","timestamp":1627759571414,"user_tz":-120,"elapsed":332,"user":{"displayName":"Nourelhouda Chiker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIRsJ2cLZ_GIRXLQrpGrOh3S-krSIQBGU8Hb_WPA=s64","userId":"04099869123671146684"}},"outputId":"622933e0-5b94-4e6a-cbd9-487debaa3445"},"source":["df.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>comments</th>\n","      <th>Topic</th>\n","      <th>hate</th>\n","      <th>cyberbullying التنمر الإلكتروني</th>\n","      <th>Abusive and Offensive Language السب والكلام الـمسيئ</th>\n","      <th>Source</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1171</th>\n","      <td>id1172</td>\n","      <td>لماذا تحاربون المذاهب الاديان اله تعال يقول دي...</td>\n","      <td>religion speech</td>\n","      <td>0</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>YouTube</td>\n","    </tr>\n","    <tr>\n","      <th>3738</th>\n","      <td>id3740</td>\n","      <td>الصحافه الاسبانيه الهلنديه استهزات بالديوث الس...</td>\n","      <td>Morocco politics</td>\n","      <td>1</td>\n","      <td>no</td>\n","      <td>yes</td>\n","      <td>YouTube</td>\n","    </tr>\n","    <tr>\n","      <th>6329</th>\n","      <td>id6331</td>\n","      <td>تكذبي وجهك صحيح لازم نقاطعو القنوات مزال تجيب ...</td>\n","      <td>Misogyny</td>\n","      <td>1</td>\n","      <td>yes</td>\n","      <td>yes</td>\n","      <td>YouTube</td>\n","    </tr>\n","    <tr>\n","      <th>2144</th>\n","      <td>id2145</td>\n","      <td>عذر اقبح ذنب وزير تجاره حاب يقولكم ورا رمضان ط...</td>\n","      <td>price hikes</td>\n","      <td>0</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>Facebook</td>\n","    </tr>\n","    <tr>\n","      <th>9024</th>\n","      <td>id9026</td>\n","      <td>الشباب راه يغتصب الزنزنات دولتك المزعومه نصاب ...</td>\n","      <td>president's speech</td>\n","      <td>1</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>Facebook</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          Id  ...    Source\n","1171  id1172  ...   YouTube\n","3738  id3740  ...   YouTube\n","6329  id6331  ...   YouTube\n","2144  id2145  ...  Facebook\n","9024  id9026  ...  Facebook\n","\n","[5 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"markdown","metadata":{"id":"k-inr06wBIk1"},"source":["TF-IDF Randomforestclassifier "]},{"cell_type":"code","metadata":{"id":"oh97FUj585Eo","executionInfo":{"status":"ok","timestamp":1627940304622,"user_tz":-120,"elapsed":5,"user":{"displayName":"Nourelhouda Chiker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIRsJ2cLZ_GIRXLQrpGrOh3S-krSIQBGU8Hb_WPA=s64","userId":"04099869123671146684"}}},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics import precision_score, recall_score, accuracy_score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import BaggingClassifier\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nQzb1yPM8vyZ","executionInfo":{"status":"ok","timestamp":1627940322383,"user_tz":-120,"elapsed":14716,"user":{"displayName":"Nourelhouda Chiker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIRsJ2cLZ_GIRXLQrpGrOh3S-krSIQBGU8Hb_WPA=s64","userId":"04099869123671146684"}},"outputId":"c3c4c78a-817c-43e8-a53d-ae680ba139a2"},"source":["tfidf = TfidfVectorizer(lowercase=False)\n","X_train_tfidf = tfidf.fit_transform(X_train)\n","X_test_tfidf = tfidf.transform(X_test)\n","\n","rf = RandomForestClassifier()\n","rf_tfidf = rf.fit(X_train_tfidf, y_train)\n","\n","y_pred = rf_tfidf.predict(X_test_tfidf)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","accuracy = accuracy_score(y_test, y_pred)\n","print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3), round(recall, 3), round(accuracy, 3)))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Precision: 0.668 / Recall: 0.744 / Accuracy: 0.651\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EGjKBSBl_3ZO","executionInfo":{"status":"ok","timestamp":1627759748854,"user_tz":-120,"elapsed":291,"user":{"displayName":"Nourelhouda Chiker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIRsJ2cLZ_GIRXLQrpGrOh3S-krSIQBGU8Hb_WPA=s64","userId":"04099869123671146684"}},"outputId":"383e1025-093a-4a1b-f21d-3fedc94b4793"},"source":["cleaned = 'يا حيوان '\n","trans = tfidf.transform([cleaned])\n","x = rf.predict(trans)[0]\n","if x == 1:\n","    print(\"hate\")\n","else:\n","    print(\"non-hate\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["hate\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9pirJe3kDLQ8"},"source":["word2vec + randomforstclassifier "]},{"cell_type":"code","metadata":{"id":"ATebrzsqBwzF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627940356418,"user_tz":-120,"elapsed":4643,"user":{"displayName":"Nourelhouda Chiker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIRsJ2cLZ_GIRXLQrpGrOh3S-krSIQBGU8Hb_WPA=s64","userId":"04099869123671146684"}},"outputId":"bf4603e4-4c6b-4909-fdfa-39f52dfa65be"},"source":["import gensim\n","import numpy as np\n","\n","w2v_model = gensim.models.Word2Vec(X_train,\n","                                   size=100,\n","                                   window=5,\n","                                   min_count=2, sg = 1)\n","\n","# Replace the words in each text message with the learned word vector\n","words = set(w2v_model.wv.index2word)\n","X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n","                         for ls in X_train])\n","X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n","                         for ls in X_test])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  if sys.path[0] == '':\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"1I0N9dDoC-Ey","executionInfo":{"status":"ok","timestamp":1627940369306,"user_tz":-120,"elapsed":397,"user":{"displayName":"Nourelhouda Chiker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIRsJ2cLZ_GIRXLQrpGrOh3S-krSIQBGU8Hb_WPA=s64","userId":"04099869123671146684"}}},"source":["# Average the word vectors for each sentence (and assign a vector of zeros if the model\n","# did not learn any of the words in the text message during training\n","X_train_vect_avg = []\n","for v in X_train_vect:\n","    if v.size:\n","        X_train_vect_avg.append(v.mean(axis=0))\n","    else:\n","        X_train_vect_avg.append(np.zeros(100, dtype=float))\n","        \n","X_test_vect_avg = []\n","for v in X_test_vect:\n","    if v.size:\n","        X_test_vect_avg.append(v.mean(axis=0))\n","    else:\n","        X_test_vect_avg.append(np.zeros(100, dtype=float))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"37Z8ZMISDByV","executionInfo":{"status":"ok","timestamp":1627940380171,"user_tz":-120,"elapsed":7795,"user":{"displayName":"Nourelhouda Chiker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIRsJ2cLZ_GIRXLQrpGrOh3S-krSIQBGU8Hb_WPA=s64","userId":"04099869123671146684"}}},"source":["rf = RandomForestClassifier()\n","rf_vect = rf.fit(X_train_vect_avg, y_train.values.ravel())"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4sTN_n5gDEv8","executionInfo":{"status":"ok","timestamp":1627940383617,"user_tz":-120,"elapsed":303,"user":{"displayName":"Nourelhouda Chiker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIRsJ2cLZ_GIRXLQrpGrOh3S-krSIQBGU8Hb_WPA=s64","userId":"04099869123671146684"}},"outputId":"e65cf30b-4196-4373-c680-316e93f7be07"},"source":["y_pred = rf_vect.predict(X_test_vect_avg)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","accuracy = accuracy_score(y_test, y_pred)\n","print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3), round(recall, 3), round(accuracy, 3)))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Precision: 0.607 / Recall: 0.724 / Accuracy: 0.585\n"],"name":"stdout"}]}]}